{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c970b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=60),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.7, 1.3)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    transforms.RandomResizedCrop((300, 300), scale=(0.7, 1.0), ratio=(0.75, 1.333)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize to ImageNet standards\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder('train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder('valid', transform=val_transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Classes\n",
    "class_names = train_dataset.classes\n",
    "print(class_names)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNet-B3\n",
    "model = models.efficientnet_b3(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, len(class_names)) \n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' in name or 'features.6' in name or 'features.7' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False \n",
    "\n",
    "# Define optimizer with different learning rates \n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.classifier.parameters(), 'lr': 0.001}, \n",
    "    {'params': [param for name, param in model.named_parameters() if 'classifier' not in name and param.requires_grad], 'lr': 0.0001} \n",
    "], lr=0.0001) \n",
    "\n",
    "# Add a learning rate scheduler \n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=10, history_file='history.json'):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_patience = 5 \n",
    "    patience_counter = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct_train = 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        val_loss, correct_val = 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        # Calculate accuracy and average loss\n",
    "        train_loss /= len(train_loader) # Calculate average train loss per batch\n",
    "        val_loss /= len(val_loader)   # Calculate average val loss per batch\n",
    "        train_acc = correct_train / len(train_loader.dataset)\n",
    "        val_acc = correct_val / len(val_loader.dataset)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # Optionally save the best model here\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break # Stop training loop\n",
    "\n",
    "    # Load the best model state if saved\n",
    "    if os.path.exists('best_model.pth'):\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "        print(\"Loaded best model state.\")\n",
    "\n",
    "    # Save final history to JSON file\n",
    "    with open(history_file, 'w') as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "# Pass the scheduler to the training function\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=scheduler, num_epochs=10) # Increased epochs as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7809e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final trained model \n",
    "torch.save(model.state_dict(), 'plant_disease_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13981e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation after training \n",
    "print(\"\\nEvaluation on Validation Set:\")\n",
    "model.eval()\n",
    "val_labels, val_preds = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "print(\"\\nClassification Report:\")\n",
    " \n",
    "# Ensure class_names is available and correct for target_names\n",
    "print(classification_report(val_labels, val_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15187e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC AUC, ensure \n",
    "try:\n",
    "    val_probs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "          inputs = inputs.to(device)\n",
    "          outputs = model(inputs)           \n",
    "          val_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "          val_probs = np.array(val_probs)\n",
    "          \n",
    "    # For multi-class, you might need to calculate per-class AUC or macro/weighted average\n",
    "    \n",
    "    if len(class_names) > 2:\n",
    "        roc_auc = roc_auc_score(val_labels, val_probs, multi_class='ovo', average='macro') \n",
    "        print(f\"\\nMacro Average ROC AUC: {roc_auc:.4f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Could not calculate ROC AUC: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during ROC AUC calculation: {e}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myplantenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
